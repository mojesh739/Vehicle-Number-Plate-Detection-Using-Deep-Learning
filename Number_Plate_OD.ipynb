{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPnnFK6BNzRl"
      },
      "outputs": [],
      "source": [
        "# ===============================================================\n",
        "# ðŸš— License Plate Detection using YOLOv3 (Darknet-format dataset)\n",
        "# Dataset: /content/License Plate.v1-yolocharacter.darknet.zip\n",
        "# ===============================================================\n",
        "\n",
        "# --- Step 1: Unzip Dataset ---\n",
        "!unzip \"/content/License Plate.v1-yolocharacter.darknet.zip\" -d dataset_license\n",
        "\n",
        "# --- Step 2: Install Dependencies ---\n",
        "try:\n",
        "    import ultralytics\n",
        "except ImportError:\n",
        "    %pip install -q ultralytics\n",
        "\n",
        "import os\n",
        "import time\n",
        "import glob\n",
        "import json\n",
        "import math\n",
        "import torch\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from ultralytics import YOLO\n",
        "import yaml\n",
        "\n",
        "# --- Step 3: Check Device ---\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device, torch.cuda.get_device_name(0) if device == \"cuda\" else \"\")\n",
        "\n",
        "# --- Step 4: Dataset YAML Configuration ---\n",
        "class_names = ['License_Plate']   # single class (whole plate)\n",
        "# If your dataset labels are per-character, replace with alphanumeric list:\n",
        "# class_names = ['0','1','2','3','4','5','6','7','8','9',\n",
        "#                'A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']\n",
        "\n",
        "dataset_path = \"/content/dataset_license\"\n",
        "data_yaml_path = os.path.join(dataset_path, \"data.yaml\")\n",
        "\n",
        "data = {\n",
        "    'train': f'{dataset_path}/train',\n",
        "    'val': f'{dataset_path}/valid',\n",
        "    'test': f'{dataset_path}/test',\n",
        "    'nc': len(class_names),\n",
        "    'names': class_names\n",
        "}\n",
        "\n",
        "with open(data_yaml_path, 'w') as f:\n",
        "    yaml.dump(data, f)\n",
        "\n",
        "# --- Step 5: Configuration ---\n",
        "DATA_YAML = data_yaml_path\n",
        "TEST_SOURCE = f\"{dataset_path}/test\"\n",
        "EPOCHS = 10\n",
        "BATCH = 16\n",
        "SIZES = [416, 608]\n",
        "RESULTS_CSV = \"/content/license_plate_results.csv\"\n",
        "ALT_RESULTS_CSV = \"/mnt/data/license_plate_results.csv\"\n",
        "os.makedirs(\"/content\", exist_ok=True)\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "# --- Step 6: Helper Functions ---\n",
        "def count_params(model_obj) -> int:\n",
        "    try:\n",
        "        return sum(p.numel() for p in model_obj.parameters())\n",
        "    except Exception:\n",
        "        return -1\n",
        "\n",
        "def find_best_weights(save_dir: str) -> str:\n",
        "    if not save_dir:\n",
        "        return \"\"\n",
        "    p = Path(save_dir) / \"weights\" / \"best.pt\"\n",
        "    return str(p) if p.exists() else \"\"\n",
        "\n",
        "def file_size_mb(path: str) -> float:\n",
        "    try:\n",
        "        return os.path.getsize(path) / (1024 * 1024.0)\n",
        "    except Exception:\n",
        "        return float(\"nan\")\n",
        "\n",
        "def extract_metrics_dict(val_results):\n",
        "    out = {\"map50\": None, \"map5095\": None, \"precision\": None, \"recall\": None, \"f1\": None}\n",
        "    if isinstance(val_results, dict):\n",
        "        out[\"map50\"] = val_results.get(\"metrics/mAP50(B)\", val_results.get(\"map50\"))\n",
        "        out[\"map5095\"] = val_results.get(\"metrics/mAP50-95(B)\", val_results.get(\"map\"))\n",
        "        out[\"precision\"] = val_results.get(\"metrics/precision(B)\", val_results.get(\"precision\"))\n",
        "        out[\"recall\"] = val_results.get(\"metrics/recall(B)\", val_results.get(\"recall\"))\n",
        "        if out[\"precision\"] and out[\"recall\"]:\n",
        "            p, r = float(out[\"precision\"]), float(out[\"recall\"])\n",
        "            out[\"f1\"] = 2 * p * r / (p + r)\n",
        "        return out\n",
        "\n",
        "    try:\n",
        "        m50 = getattr(getattr(val_results, \"box\", None), \"map50\", None)\n",
        "        m5095 = getattr(getattr(val_results, \"box\", None), \"map\", None)\n",
        "        p = getattr(val_results, \"precision\", None)\n",
        "        r = getattr(val_results, \"recall\", None)\n",
        "        f1 = getattr(val_results, \"f1\", None)\n",
        "        out[\"map50\"] = float(m50) if m50 is not None else None\n",
        "        out[\"map5095\"] = float(m5095) if m5095 is not None else None\n",
        "        out[\"precision\"] = float(p) if p is not None else None\n",
        "        out[\"recall\"] = float(r) if r is not None else None\n",
        "        out[\"f1\"] = float(f1) if f1 is not None else None\n",
        "        if out[\"f1\"] is None and out[\"precision\"] and out[\"recall\"]:\n",
        "            P, R = out[\"precision\"], out[\"recall\"]\n",
        "            out[\"f1\"] = 2 * P * R / (P + R)\n",
        "    except Exception:\n",
        "        pass\n",
        "    return out\n",
        "\n",
        "def time_training(model, imgsz: int, data_yaml: str, epochs: int, batch: int):\n",
        "    start = time.time()\n",
        "    train_results = model.train(data=data_yaml, epochs=epochs, imgsz=imgsz, batch=batch, verbose=True)\n",
        "    end = time.time()\n",
        "    train_time_min = (end - start) / 60.0\n",
        "    save_dir = \"\"\n",
        "    try:\n",
        "        save_dir = str(model.trainer.save_dir)\n",
        "    except Exception:\n",
        "        pass\n",
        "    return train_results, train_time_min, save_dir\n",
        "\n",
        "def validate_metrics(model, data_yaml: str):\n",
        "    val_results = model.val(data=data_yaml, verbose=True)\n",
        "    return extract_metrics_dict(val_results)\n",
        "\n",
        "def warmup_predict(model, test_source: str):\n",
        "    try:\n",
        "        one = None\n",
        "        if os.path.isdir(test_source):\n",
        "            exts = (\"*.jpg\",\"*.jpeg\",\"*.png\",\"*.bmp\")\n",
        "            files = []\n",
        "            for e in exts:\n",
        "                files += glob.glob(os.path.join(test_source, \"**\", e), recursive=True)\n",
        "            if files:\n",
        "                one = files[0]\n",
        "        if one:\n",
        "            _ = model.predict(source=one, verbose=False)\n",
        "    except Exception as e:\n",
        "        print(\"Warmup skipped:\", e)\n",
        "\n",
        "def time_inference_folder(model, test_source: str):\n",
        "    exts = (\"*.jpg\",\"*.jpeg\",\"*.png\",\"*.bmp\")\n",
        "    files = []\n",
        "    if os.path.isdir(test_source):\n",
        "        for e in exts:\n",
        "            files += glob.glob(os.path.join(test_source, \"**\", e), recursive=True)\n",
        "    else:\n",
        "        files = [test_source] if os.path.isfile(test_source) else []\n",
        "    n = len(files)\n",
        "    if n == 0:\n",
        "        print(f\"No images found in {test_source}. Inference timing will be NaN.\")\n",
        "        return float(\"nan\")\n",
        "    warmup_predict(model, test_source)\n",
        "    t1 = time.time()\n",
        "    _ = model.predict(source=test_source, verbose=False)\n",
        "    t2 = time.time()\n",
        "    avg_ms = ((t2 - t1) / n) * 1000.0\n",
        "    return avg_ms\n",
        "\n",
        "# --- Step 7: Main Experiment Function ---\n",
        "def run_experiment(imgsz: int):\n",
        "    print(f\"\\n===== Running experiment at imgsz={imgsz} =====\")\n",
        "    model = YOLO(\"yolov3u.pt\")\n",
        "    model.to(device)\n",
        "\n",
        "    num_params = count_params(model.model)\n",
        "    train_results, train_time_min, save_dir = time_training(model, imgsz, DATA_YAML, EPOCHS, BATCH)\n",
        "    best_w = find_best_weights(save_dir)\n",
        "    best_size_mb = file_size_mb(best_w) if best_w else float(\"nan\")\n",
        "    metrics = validate_metrics(model, DATA_YAML)\n",
        "    avg_ms = time_inference_folder(model, TEST_SOURCE)\n",
        "\n",
        "    row = {\n",
        "        \"input_size\": imgsz,\n",
        "        \"train_time_min\": train_time_min,\n",
        "        \"inference_ms_per_image\": avg_ms,\n",
        "        \"map50\": metrics.get(\"map50\"),\n",
        "        \"map50_95\": metrics.get(\"map5095\"),\n",
        "        \"precision\": metrics.get(\"precision\"),\n",
        "        \"recall\": metrics.get(\"recall\"),\n",
        "        \"f1\": metrics.get(\"f1\"),\n",
        "        \"num_params\": num_params,\n",
        "        \"best_weights_path\": best_w,\n",
        "        \"best_weights_size_mb\": best_size_mb,\n",
        "        \"runs_dir\": save_dir\n",
        "    }\n",
        "    return row\n",
        "\n",
        "# --- Step 8: Run Experiments for Sizes ---\n",
        "all_rows = []\n",
        "for s in SIZES:\n",
        "    row = run_experiment(s)\n",
        "    all_rows.append(row)\n",
        "\n",
        "df = pd.DataFrame(all_rows)\n",
        "display(df)\n",
        "\n",
        "# --- Step 9: Save Results ---\n",
        "df.to_csv(RESULTS_CSV, index=False)\n",
        "try:\n",
        "    os.makedirs(\"/mnt/data\", exist_ok=True)\n",
        "    df.to_csv(ALT_RESULTS_CSV, index=False)\n",
        "except Exception as e:\n",
        "    print(\"Could not save ALT_RESULTS_CSV:\", e)\n",
        "\n",
        "print(\"Saved results:\", RESULTS_CSV)\n",
        "\n",
        "# --- Step 10: Visualization ---\n",
        "plt.figure()\n",
        "plt.plot(df[\"input_size\"], df[\"map50\"], marker=\"o\")\n",
        "plt.title(\"mAP50 vs Input Size\")\n",
        "plt.xlabel(\"Input Size\")\n",
        "plt.ylabel(\"mAP50\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(df[\"input_size\"], df[\"train_time_min\"], marker=\"o\")\n",
        "plt.title(\"Training Time (min) vs Input Size\")\n",
        "plt.xlabel(\"Input Size\")\n",
        "plt.ylabel(\"Training Time (min)\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(df[\"input_size\"], df[\"inference_ms_per_image\"], marker=\"o\")\n",
        "plt.title(\"Inference Speed (ms/image) vs Input Size\")\n",
        "plt.xlabel(\"Input Size\")\n",
        "plt.ylabel(\"ms per image\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# --- Step 11: Test Visualization ---\n",
        "model_416 = YOLO(\"/content/runs/detect/train/weights/best.pt\")\n",
        "model_608 = YOLO(\"/content/runs/detect/train2/weights/best.pt\")\n",
        "\n",
        "import random, glob\n",
        "test_imgs = random.sample(glob.glob(f\"{dataset_path}/test/*.jpg\"), 5)\n",
        "\n",
        "from IPython.display import Image, display\n",
        "for img in test_imgs:\n",
        "    r1 = model_416.predict(img, save=False)\n",
        "    r2 = model_608.predict(img, save=False)\n",
        "    display(r1[0].plot())\n",
        "    display(r2[0].plot())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oWM788j-N7bC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}